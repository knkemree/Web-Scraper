{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Check the created excel file!\n",
      "Excel file: parsed products_20200312-1326.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_external_url</th>\n",
       "      <th>name</th>\n",
       "      <th>sku</th>\n",
       "      <th>price_wholesale</th>\n",
       "      <th>price</th>\n",
       "      <th>cost</th>\n",
       "      <th>status_id</th>\n",
       "      <th>category_names</th>\n",
       "      <th>barcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://cdn10.bigcommerce.com/s-x63ch/products...</td>\n",
       "      <td>iPhone 11 Dual Layer Protection Case Cover  - ...</td>\n",
       "      <td>61-DLP-BLK</td>\n",
       "      <td>2.54</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1</td>\n",
       "      <td>iPhone 11 (6.1\")</td>\n",
       "      <td>193499945711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://cdn10.bigcommerce.com/s-x63ch/products...</td>\n",
       "      <td>iPhone 11 Dual Layer Protection Case Cover  - ...</td>\n",
       "      <td>61-DLP-GLD</td>\n",
       "      <td>2.54</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1</td>\n",
       "      <td>iPhone 11 (6.1\")</td>\n",
       "      <td>449127957919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://cdn10.bigcommerce.com/s-x63ch/products...</td>\n",
       "      <td>iPhone 11 Dual Layer Protection Case Cover  - ...</td>\n",
       "      <td>61-DLP-GRN</td>\n",
       "      <td>2.54</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1</td>\n",
       "      <td>iPhone 11 (6.1\")</td>\n",
       "      <td>639560736744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://cdn10.bigcommerce.com/s-x63ch/products...</td>\n",
       "      <td>iPhone 11 Dual Layer Protection Case Cover  - ...</td>\n",
       "      <td>61-DLP-GRY</td>\n",
       "      <td>2.54</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1</td>\n",
       "      <td>iPhone 11 (6.1\")</td>\n",
       "      <td>323458621186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://cdn10.bigcommerce.com/s-x63ch/products...</td>\n",
       "      <td>iPhone 11 Dual Layer Protection Case Cover  - ...</td>\n",
       "      <td>61-DLP-HBLU</td>\n",
       "      <td>2.54</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1</td>\n",
       "      <td>iPhone 11 (6.1\")</td>\n",
       "      <td>686685750672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  photo_external_url  \\\n",
       "0  https://cdn10.bigcommerce.com/s-x63ch/products...   \n",
       "1  https://cdn10.bigcommerce.com/s-x63ch/products...   \n",
       "2  https://cdn10.bigcommerce.com/s-x63ch/products...   \n",
       "3  https://cdn10.bigcommerce.com/s-x63ch/products...   \n",
       "4  https://cdn10.bigcommerce.com/s-x63ch/products...   \n",
       "\n",
       "                                                name          sku  \\\n",
       "0  iPhone 11 Dual Layer Protection Case Cover  - ...   61-DLP-BLK   \n",
       "1  iPhone 11 Dual Layer Protection Case Cover  - ...   61-DLP-GLD   \n",
       "2  iPhone 11 Dual Layer Protection Case Cover  - ...   61-DLP-GRN   \n",
       "3  iPhone 11 Dual Layer Protection Case Cover  - ...   61-DLP-GRY   \n",
       "4  iPhone 11 Dual Layer Protection Case Cover  - ...  61-DLP-HBLU   \n",
       "\n",
       "   price_wholesale  price  cost status_id    category_names       barcode  \n",
       "0             2.54   6.25  2.42         1  iPhone 11 (6.1\")  193499945711  \n",
       "1             2.54   6.25  2.42         1  iPhone 11 (6.1\")  449127957919  \n",
       "2             2.54   6.25  2.42         1  iPhone 11 (6.1\")  639560736744  \n",
       "3             2.54   6.25  2.42         1  iPhone 11 (6.1\")  323458621186  \n",
       "4             2.54   6.25  2.42         1  iPhone 11 (6.1\")  686685750672  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  CHILD CATEGORY PARSER !!!!!!!\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "import csv\n",
    "from fuzzywuzzy import fuzz,process\n",
    "import numpy as np\n",
    "\n",
    "## initializing the UserAgent object\n",
    "headers = {\"User-Agent\" : 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'}\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\") # today's date\n",
    "\n",
    "def make_soup(url):\n",
    "    ## getting the reponse from the page using get method of requests module\n",
    "    page = requests.get(url, headers=headers, allow_redirects=False)\n",
    "    \n",
    "    ## storing the content of the page in a variable\n",
    "    html = page.content\n",
    "    \n",
    "    ## creating BeautifulSoup object\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    return soup  \n",
    "\n",
    "\n",
    "\n",
    "main_link = 'https://www.phonelcdparts.com/61-dlp/'\n",
    "\n",
    "\n",
    "\n",
    "souped_main_link = make_soup(main_link)\n",
    "\n",
    "urls = []\n",
    "for i in souped_main_link.find_all('div', {'class':'product-imag'}):\n",
    "    \n",
    "    urls.append(i.find_all('a')[1]['href']) \n",
    "urls\n",
    "\n",
    "web_content_list = []\n",
    "for i in urls:\n",
    "        souped_links=make_soup(i)\n",
    "        \n",
    "        c = souped_links.find_all('div', {'class':'left-content'})\n",
    "        for z in c:\n",
    "            web_content_dict = {}\n",
    "            link = z.find('img')['src']\n",
    "            web_content_dict[\"photo_external_url\"]=link\n",
    "        \n",
    "       \n",
    "    \n",
    "        for names, sku, price in zip (souped_links.find_all('h1'), \n",
    "                           souped_links.find_all('span', class_='VariationProductSKU'),\n",
    "                            souped_links.find_all('span', class_='VariationProductPrice'),\n",
    "                                      \n",
    "                          ):\n",
    "        \n",
    "        \n",
    "            web_content_dict[\"name\"]=names.text\n",
    "            web_content_dict[\"sku\"]=sku.text.replace('\\n', ' ').replace(\" \", \"\")\n",
    "            web_content_dict[\"price_wholesale\"]=price.text\n",
    "            \n",
    "            web_content_dict[\"price\"]=price.text\n",
    "            web_content_dict[\"cost\"]=price.text\n",
    "            \n",
    "            web_content_list.append(web_content_dict)\n",
    "            \n",
    "        web_content_dict[\"status_id\"] = ' '.join(map(str, [i for i in range(1,2)]))\n",
    "        \n",
    "        web_content_dict[\"category_names\"] = souped_main_link.find_all('div', {'class':'Block Moveable Panel Breadcrumb'})[0]('ul')[0]('li')[3].text \n",
    "\n",
    "web_content_list \n",
    "\n",
    "df = pd.DataFrame(web_content_list)     \n",
    "df[\"price_wholesale\"]=df[\"price_wholesale\"].str.replace(\"$\",\" \")\n",
    "df[\"price_wholesale\"]=df[\"price_wholesale\"].apply(pd.to_numeric, errors='coerce').add(0.04)\n",
    "df[\"price\"]=df[\"price\"].str.replace(\"$\",\" \")\n",
    "df[\"price\"]=df[\"price\"].apply(pd.to_numeric, errors='coerce').add(df[\"price\"].apply(pd.to_numeric, errors='coerce').div(2/3)).round(2)\n",
    "df[\"cost\"]=df[\"cost\"].str.replace(\"$\",\" \")\n",
    "df[\"cost\"] = df[\"cost\"].apply(pd.to_numeric, errors='coerce').sub(df[\"cost\"].apply(pd.to_numeric, errors='coerce').div(33)).round(2)\n",
    "df['barcode'] = pd.DataFrame(np.random.randint(100000000000,999999999999,size=(int(len(web_content_list)), 1), dtype=np.int64))\n",
    "#df[\"row_no\"]=[i for i in range(1,len(df)+1)] \n",
    "\n",
    "df.to_csv('parsed products_'+str(timestr)+'.csv', index=False)    \n",
    "print(\"Done! Check the created excel file!\")\n",
    "print('Excel file: parsed products_'+ str(timestr)+'.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deneme amacli. case kategorisinde kategori boxlari ic ice. onu halletmeye calisyorum\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "import csv\n",
    "from fuzzywuzzy import fuzz,process\n",
    "import numpy as np\n",
    "\n",
    "## initializing the UserAgent object\n",
    "headers = {\"User-Agent\" : 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'}\n",
    "timestr2 = time.strftime(\"%Y%m%d-%H%M\") # today's date\n",
    "\n",
    "def make_soup(url):\n",
    "    ## getting the reponse from the page using get method of requests module\n",
    "    page = requests.get(url, headers=headers, allow_redirects=False)\n",
    "    \n",
    "    ## storing the content of the page in a variable\n",
    "    html = page.content\n",
    "    \n",
    "    ## creating BeautifulSoup object\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    return soup \n",
    "\n",
    "def parse_cats(maine_link):\n",
    "    \n",
    "    \n",
    "    souped_main_linkd = make_soup(maine_link)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    urld = []\n",
    "    try:\n",
    "        hj = souped_main_linkd.find_all('div', class_='SubCategoryList')\n",
    "        \n",
    "        for i in hj[1].find('ul').find_all('li'):\n",
    "            lne = i.find_all('a')[0]['href']\n",
    "            try:\n",
    "                n_ln = make_soup(lne).find_all('ul', {'class':'PagingList'})[0].find_all('li')\n",
    "                for kf in range(1, len(n_ln)+1):\n",
    "                    xy = str(ln)+'?sort=featured&page='+str(kf)\n",
    "                    urld.append(xy)\n",
    "                \n",
    "            except:\n",
    "                urld.append(lne)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "        \n",
    "    except:    \n",
    "        for i in souped_main_linkd.find_all('a', {'class':'btn-block'}):\n",
    "        \n",
    "    \n",
    "            ln = i['href']\n",
    "            try:\n",
    "                n_ln = make_soup(ln).find_all('ul', {'class':'PagingList'})[0].find_all('li')\n",
    "                for kf in range(1, len(n_ln)+1):\n",
    "                    xy = str(ln)+'?sort=featured&page='+str(kf)\n",
    "                    urld.append(xy)\n",
    "                \n",
    "            except:\n",
    "                urld.append(ln)\n",
    "    print(urld)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    urlds = [] \n",
    "    rows = []\n",
    "    try:\n",
    "        for g in urld:\n",
    "            \n",
    "            for i in make_soup(g).find_all('a', {'class':'btn-block'}):\n",
    "                lnc = i['href']\n",
    "                print(lnc)\n",
    "                y = make_soup(lnc)\n",
    "                links =[]\n",
    "                for d in y.find_all('div', {'class':'product-imag'}):\n",
    "        \n",
    "                    links.append(d.find_all('a')[1]['href'])\n",
    "                    rows.append(len(links))\n",
    "            \n",
    "                links\n",
    "    \n",
    "                for f in links:\n",
    "                    souped_links=make_soup(f)\n",
    "        \n",
    "                    c = souped_links.find_all('div', {'class':'left-content'})\n",
    "                    for z in c:\n",
    "                        web_content_dict = {}\n",
    "                        link = z.find('img')['src']\n",
    "            \n",
    "                        web_content_dict[\"photo_external_url\"]=link\n",
    "                    for names, sku, price in zip (souped_links.find_all('h1'), \n",
    "                           souped_links.find_all('span', class_='VariationProductSKU'),\n",
    "                            souped_links.find_all('span', class_='VariationProductPrice'),          \n",
    "                              ):\n",
    "                        print(names.text)\n",
    "                        web_content_dict[\"name\"]=names.text\n",
    "                        web_content_dict[\"sku\"]=sku.text.replace('\\n', ' ').replace(\" \", \"\")\n",
    "                        web_content_dict[\"price_wholesale\"]=price.text\n",
    "            \n",
    "                        web_content_dict[\"price\"]=price.text\n",
    "                        web_content_dict[\"cost\"]=price.text\n",
    "            \n",
    "                        urlds.append(web_content_dict)\n",
    "                    web_content_dict[\"status_id\"] = ' '.join(map(str, [i for i in range(1,2)]))\n",
    "        \n",
    "                    web_content_dict[\"category_ids\"] = y.find_all('div', {'class':'Block Moveable Panel Breadcrumb'})[0]('ul')[0]('li')[3].text\n",
    "        \n",
    "    except:\n",
    "        for z in urld:\n",
    "            y = make_soup(z)\n",
    "        \n",
    "            links =[]\n",
    "            for d in y.find_all('div', {'class':'product-imag'}):\n",
    "        \n",
    "                links.append(d.find_all('a')[1]['href'])\n",
    "                rows.append(len(links))\n",
    "            \n",
    "            links\n",
    "    \n",
    "            for f in links:\n",
    "                souped_links=make_soup(f)\n",
    "        \n",
    "                c = souped_links.find_all('div', {'class':'left-content'})\n",
    "                for z in c:\n",
    "                    web_content_dict = {}\n",
    "                    link = z.find('img')['src']\n",
    "            \n",
    "                    web_content_dict[\"photo_external_url\"]=link\n",
    "                for names, sku, price in zip (souped_links.find_all('h1'), \n",
    "                           souped_links.find_all('span', class_='VariationProductSKU'),\n",
    "                            souped_links.find_all('span', class_='VariationProductPrice'),\n",
    "                                      \n",
    "                          ):\n",
    "                    print(names.text)\n",
    "                    web_content_dict[\"name\"]=names.text\n",
    "                    web_content_dict[\"sku\"]=sku.text.replace('\\n', ' ').replace(\" \", \"\")\n",
    "                    web_content_dict[\"price_wholesale\"]=price.text\n",
    "            \n",
    "                    web_content_dict[\"price\"]=price.text\n",
    "                    web_content_dict[\"cost\"]=price.text\n",
    "            \n",
    "                    urlds.append(web_content_dict)\n",
    "                web_content_dict[\"status_id\"] = ' '.join(map(str, [i for i in range(1,2)]))\n",
    "        \n",
    "                web_content_dict[\"category_ids\"] = y.find_all('div', {'class':'Block Moveable Panel Breadcrumb'})[0]('ul')[0]('li')[3].text\n",
    "        \n",
    "            \n",
    "    print(urlds)\n",
    "\n",
    "    df = pd.DataFrame(urlds)\n",
    "    df[\"price_wholesale\"]=df[\"price_wholesale\"].str.replace(\"$\",\" \")\n",
    "    df[\"price_wholesale\"]=df[\"price_wholesale\"].apply(pd.to_numeric, errors='coerce').add(0.04).round(2)\n",
    "    df[\"price\"]=df[\"price\"].str.replace(\"$\",\" \")\n",
    "    df[\"price\"]=df[\"price\"].apply(pd.to_numeric, errors='coerce').add(df[\"price\"].apply(pd.to_numeric, errors='coerce').div(2/3)).round(2)\n",
    "    df[\"cost\"]=df[\"cost\"].str.replace(\"$\",\" \")\n",
    "    df[\"cost\"] = df[\"cost\"].apply(pd.to_numeric, errors='coerce').sub(df[\"cost\"].apply(pd.to_numeric, errors='coerce').div(33)).round(2)\n",
    "    df['barcode'] = pd.DataFrame(np.random.randint(100000000000,999999999999,size=(int(len(urlds)), 1), dtype=np.int64))\n",
    "    \n",
    "    g = df.groupby('category_ids', as_index=False)\n",
    "    df['row_no'] = g.cumcount()\n",
    "    \n",
    "    y = df.groupby(['name'])['category_ids'].apply(','.join).reset_index()\n",
    "    df2 = df.merge(y, left_on='name', right_on='name', how='left').drop(columns='category_ids_x').rename(columns={\"category_ids_y\": \"category_names\"})\n",
    "    df2.to_csv('parsed products_'+str(timestr2)+'.csv', index=False) \n",
    "    print(\"Done! Check the created excel file!\")\n",
    "    print('Excel file: parsed products_'+ str(timestr2)+'.csv')\n",
    "    df2.head()\n",
    "    \n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.phonelcdparts.com/galaxy-note-10-plus/', 'https://www.phonelcdparts.com/galaxy-note-10/', 'https://www.phonelcdparts.com/galaxy-note-9/?sort=featured&page=1', 'https://www.phonelcdparts.com/galaxy-note-9/?sort=featured&page=2', 'https://www.phonelcdparts.com/galaxy-note-8/?sort=featured&page=1', 'https://www.phonelcdparts.com/galaxy-note-8/?sort=featured&page=2', 'https://www.phonelcdparts.com/samsung-parts/samsung-galaxy-note-5/?sort=featured&page=1', 'https://www.phonelcdparts.com/samsung-parts/samsung-galaxy-note-5/?sort=featured&page=2', 'https://www.phonelcdparts.com/samsung-parts/samsung-galaxy-note-4/', 'https://www.phonelcdparts.com/samsung-parts/samsung-galaxy-note-3/', 'https://www.phonelcdparts.com/samsung-parts/samsung-galaxy-note-2/']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'price_wholesale'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'price_wholesale'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-fada9b2669b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmaine_link\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.phonelcdparts.com/galaxy-note-parts/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mparse_cats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaine_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-63-cf6a97bb29e9>\u001b[0m in \u001b[0;36mparse_cats\u001b[1;34m(maine_link)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"price_wholesale\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"price_wholesale\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"$\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"price_wholesale\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"price_wholesale\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coerce'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.04\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"price\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"price\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"$\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2994\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2995\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2996\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'price_wholesale'"
     ]
    }
   ],
   "source": [
    "maine_link = 'https://www.phonelcdparts.com/galaxy-note-parts/'\n",
    "parse_cats(maine_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont use it for now\n",
    "# run this code to import the output to primemobileparts.com\n",
    "\n",
    "driver = webdriver.Chrome('C:/Users/prime/OneDrive/Desktop/chromedriver.exe')\n",
    "driver.get (\"https://www.primemobileparts.com/login\")\n",
    "driver.find_element_by_id(\"email\").send_keys(\"konakziyaemre@gmail.com\")\n",
    "driver.find_element_by_id (\"password\").send_keys(\"deneme\")\n",
    "driver.find_element_by_class_name(\"btn-primary\").click()\n",
    "driver.get(\"https://www.primemobileparts.com/admin/product-import\")\n",
    "driver.find_element_by_id(\"upload\").send_keys('parsed products_'+str(timestr)+'.csv')\n",
    "driver.find_element_by_class_name(\"btn-primary\").click()\n",
    "\n",
    "time.sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.phonelcdparts.com/htc-u12-plus/', 'https://www.phonelcdparts.com/htc-u12/', 'https://www.phonelcdparts.com/htc-u11/', 'https://www.phonelcdparts.com/htc-u11-life/', 'https://www.phonelcdparts.com/htc-u-ultra/', 'https://www.phonelcdparts.com/htc-parts/one-m10-parts/', 'https://www.phonelcdparts.com/htc-parts/htc-one-m9/', 'https://www.phonelcdparts.com/htc-parts/htc-one-m8/', 'https://www.phonelcdparts.com/htc-desire-626s/', 'https://www.phonelcdparts.com/htc-parts/htc-desire-626s/', 'https://www.phonelcdparts.com/htc-parts/htc-desire-816/', 'https://www.phonelcdparts.com/htc-parts/htc-desire-530/', 'https://www.phonelcdparts.com/htc-parts/htc-first-pm/', 'https://www.phonelcdparts.com/htc-parts/htc-one-x/']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "souped_main_linkd = make_soup(maine_link)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "urld = []\n",
    "try:\n",
    "    hj = souped_main_linkd.find_all('div', class_='SubCategoryList')\n",
    "        \n",
    "    for i in hj[1].find('ul').find_all('li'):\n",
    "        lne = i.find_all('a')[0]['href']\n",
    "        try:\n",
    "            n_ln = make_soup(lne).find_all('ul', {'class':'PagingList'})[0].find_all('li')\n",
    "            for kf in range(1, len(n_ln)+1):\n",
    "                xy = str(ln)+'?sort=featured&page='+str(kf)\n",
    "                urld.append(xy)\n",
    "                \n",
    "        except:\n",
    "            urld.append(lne)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "        \n",
    "except:    \n",
    "    for i in souped_main_linkd.find_all('a', {'class':'btn-block'}):\n",
    "        \n",
    "    \n",
    "        ln = i['href']\n",
    "        try:\n",
    "            n_ln = make_soup(ln).find_all('ul', {'class':'PagingList'})[0].find_all('li')\n",
    "            for kf in range(1, len(n_ln)+1):\n",
    "                xy = str(ln)+'?sort=featured&page='+str(kf)\n",
    "                urld.append(xy)\n",
    "                \n",
    "        except:\n",
    "            urld.append(ln)\n",
    "print(urld)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "urlds = [] \n",
    "rows = []\n",
    "try:\n",
    "    for g in urld:\n",
    "            \n",
    "        for i in make_soup(g).find_all('a', {'class':'btn-block'}):\n",
    "            lnc = i['href']\n",
    "            print(lnc)\n",
    "            y = make_soup(lnc)\n",
    "            links =[]\n",
    "            for d in y.find_all('div', {'class':'product-imag'}):\n",
    "        \n",
    "                links.append(d.find_all('a')[1]['href'])\n",
    "                rows.append(len(links))\n",
    "            \n",
    "            links\n",
    "    \n",
    "            for f in links:\n",
    "                souped_links=make_soup(f)\n",
    "        \n",
    "                c = souped_links.find_all('div', {'class':'left-content'})\n",
    "                for z in c:\n",
    "                    web_content_dict = {}\n",
    "                    link = z.find('img')['src']\n",
    "            \n",
    "                    web_content_dict[\"photo_external_url\"]=link\n",
    "                for names, sku, price in zip (souped_links.find_all('h1'), \n",
    "                        souped_links.find_all('span', class_='VariationProductSKU'),\n",
    "                        souped_links.find_all('span', class_='VariationProductPrice'),          \n",
    "                            ):\n",
    "                    print(names.text)\n",
    "                    web_content_dict[\"name\"]=names.text\n",
    "                    web_content_dict[\"sku\"]=sku.text.replace('\\n', ' ').replace(\" \", \"\")\n",
    "                    web_content_dict[\"price_wholesale\"]=price.text\n",
    "            \n",
    "                    web_content_dict[\"price\"]=price.text\n",
    "                    web_content_dict[\"cost\"]=price.text\n",
    "            \n",
    "                    urlds.append(web_content_dict)\n",
    "                web_content_dict[\"status_id\"] = ' '.join(map(str, [i for i in range(1,2)]))\n",
    "        \n",
    "                web_content_dict[\"category_ids\"] = y.find_all('div', {'class':'Block Moveable Panel Breadcrumb'})[0]('ul')[0]('li')[3].text\n",
    "        \n",
    "except:\n",
    "    for z in urld:\n",
    "        y = make_soup(z)\n",
    "        \n",
    "        links =[]\n",
    "        for d in y.find_all('div', {'class':'product-imag'}):\n",
    "        \n",
    "            links.append(d.find_all('a')[1]['href'])\n",
    "            rows.append(len(links))\n",
    "            \n",
    "        links\n",
    "    \n",
    "        for f in links:\n",
    "            souped_links=make_soup(f)\n",
    "        \n",
    "            c = souped_links.find_all('div', {'class':'left-content'})\n",
    "            for z in c:\n",
    "                web_content_dict = {}\n",
    "                link = z.find('img')['src']\n",
    "            \n",
    "                web_content_dict[\"photo_external_url\"]=link\n",
    "            for names, sku, price in zip (souped_links.find_all('h1'), \n",
    "                        souped_links.find_all('span', class_='VariationProductSKU'),\n",
    "                        souped_links.find_all('span', class_='VariationProductPrice'),\n",
    "                                      \n",
    "                        ):\n",
    "                print(names.text)\n",
    "                web_content_dict[\"name\"]=names.text\n",
    "                web_content_dict[\"sku\"]=sku.text.replace('\\n', ' ').replace(\" \", \"\")\n",
    "                web_content_dict[\"price_wholesale\"]=price.text\n",
    "            \n",
    "                web_content_dict[\"price\"]=price.text\n",
    "                web_content_dict[\"cost\"]=price.text\n",
    "            \n",
    "                urlds.append(web_content_dict)\n",
    "            web_content_dict[\"status_id\"] = ' '.join(map(str, [i for i in range(1,2)]))\n",
    "        \n",
    "            web_content_dict[\"category_ids\"] = y.find_all('div', {'class':'Block Moveable Panel Breadcrumb'})[0]('ul')[0]('li')[3].text\n",
    "        \n",
    "            \n",
    "print(urlds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.phonelcdparts.com/htc-u12-plus/', 'https://www.phonelcdparts.com/htc-u12/', 'https://www.phonelcdparts.com/htc-u11/', 'https://www.phonelcdparts.com/htc-u11-life/', 'https://www.phonelcdparts.com/htc-u-ultra/', 'https://www.phonelcdparts.com/htc-parts/one-m10-parts/', 'https://www.phonelcdparts.com/htc-parts/htc-one-m9/', 'https://www.phonelcdparts.com/htc-parts/htc-one-m8/', 'https://www.phonelcdparts.com/htc-desire-626s/', 'https://www.phonelcdparts.com/htc-parts/htc-desire-626s/', 'https://www.phonelcdparts.com/htc-parts/htc-desire-816/', 'https://www.phonelcdparts.com/htc-parts/htc-desire-530/', 'https://www.phonelcdparts.com/htc-parts/htc-first-pm/', 'https://www.phonelcdparts.com/htc-parts/htc-one-x/']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "maine_link = 'https://www.phonelcdparts.com/htc/'\n",
    "parse_cats(maine_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scr_list_page = make_soup('https://www.onesourcesuppliers.com/search?query=033991052376&query_category=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_cont = scr_list_page.find_all('h2', class_='col-xs-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(product_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to navigate the US-China trade war\n",
      "Shenzhen’s speculative stocks defy coronavirus\n",
      "Coronavirus shutdown leaves China with cleaner air to breathe Premium\n",
      "Nouriel Roubini: Markets are too complacent about virus\n",
      "China calls on foreigners to drain $1.5tn bad-debt swamp Premium\n",
      "China charters flights to get people back to work\n",
      "Global inventories at 7-year low prior to coronavirus hit  Premium\n",
      "Coronavirus: Chinese carmakers struggle with disruption\n",
      "The Chinese super-regulator taking on the coronavirus\n",
      "Chinese carmakers accelerate drive into India\n",
      "US: don’t give China control of intellectual property group   \n",
      "The virus crisis and the decoupling of global trade\n",
      "Deere profits boosted by relaxation of US-China trade spat\n",
      "China reopens bond futures market to big local banks\n",
      "The under appreciated importance of non-woven markets\n",
      "Coronavirus: Apple supplier Foxconn warns over revenue hit\n",
      "China banks cut rate to prop up coronavirus-hit economy\n",
      "Chinese government bond yields hit four-year low\n",
      "PBoC will help China recover quickly from coronavirus\n",
      "How a Democrat might worsen the US-China feud\n",
      "Investors hunt alt-data to track coronavirus effects\n",
      "Singapore’s empty airport highlights coronavirus impact on Asia\n",
      "Coronavirus gives China get-out clause for buying US energy\n",
      "Coronavirus: WHO cautions over figures showing slowdown in infections - as it happened\n",
      "Global stocks rally on stimulus hopes\n",
      "China’s economy at a glance\n",
      "Martin Wolf’s China file\n"
     ]
    }
   ],
   "source": [
    "ft_page = make_soup('https://www.ft.com/chinese-economy')\n",
    "for i in ft_page.find_all('div', class_='o-teaser__heading'):\n",
    "    title  = i.text\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global supply chains are at risk as the world’s two biggest economies threaten to decouple\n",
      "Tech-focused ChiNext soars despite outbreak’s threat to wider Chinese economy\n",
      "Pollution falls sharply following measures to control the infection \n",
      "Assumption after assumption about the impact of the outbreak has been proven wrong\n",
      "Goldman, Oaktree and Lone Star see massive buying opportunities\n",
      "World’s second-largest economy begins to restart after coronavirus shutdown\n",
      "Manufacturers’ vulnerability to supply chain shock intensified by rundown in stock levels\n",
      "Annual motor show is delayed, production lines are only just restarting and dealerships are empty of customers\n",
      "Guo Shuqing’s legacy will hinge on whether he can counter outbreak’s economic impact\n",
      "Market predicted to become third largest with number of first-time buyers set to increase\n",
      "Chinese nationals head four UN specialised agencies, no other country leads more than one \n",
      "Coronavirus succeeds where politicians failed to curtail globalisation\n",
      "Agricultural equipment maker posts unexpected jump in earnings following ‘phase one’ deal\n",
      "Pilot to include country’s five largest state-owned lenders and qualifying insurers\n",
      "Face masks. Global supply chains need them because manufacturing needs them.\n",
      "Announcement is clearest indication yet of outbreak’s impact on the global technology supply chain\n",
      "S&P warns of $1.1tn surge in bad loans and annual economic growth as low as 4.4%\n",
      "US, European investors bet that Beijing will deploy stimulus to counter virus effects\n",
      "Deputy governor: central bank has ample policy room to stabilise the economy\n",
      "Donald Trump could turn out to be better at containing Beijing than high-minded idealists\n",
      "Analytics companies mine figures on everything from traffic jams to food orders in China\n",
      "Outbreak is hitting some of the world’s busiest aviation and maritime trade corridors\n",
      "Hard to see how Beijing can ramp up oil and gas imports in line with ‘phase one’ deal\n",
      "CSI 300 gains as traders bank on Beijing easing further to cushion coronavirus impact\n"
     ]
    }
   ],
   "source": [
    "for i in ft_page.find_all('p', class_='o-teaser__standfirst'):\n",
    "    description = i.text\n",
    "    print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ft.com/content/6124beb8-5724-11ea-abe5-8e03987b7b20\n",
      "https://www.ft.com/content/8606d04a-5931-11ea-a528-dd0f971febbc\n",
      "https://www.ft.com/content/ab75fdd8-6c84-4e81-b8df-43a2c8eb7568\n",
      "https://www.ft.com/content/e0ca01ee-57cb-11ea-abe5-8e03987b7b20\n",
      "https://www.ft.com/content/b41547b2-9971-48b2-a74f-a429402b485d\n",
      "https://www.ft.com/content/b7abf464-5791-11ea-a528-dd0f971febbc\n",
      "https://www.ft.com/content/79250da6-61c2-4173-8176-3a0a526f1e06\n",
      "https://www.ft.com/content/b5392370-53b6-11ea-8841-482eed0038b1\n",
      "https://www.ft.com/content/fa003908-53a7-11ea-8841-482eed0038b1\n",
      "https://www.ft.com/content/cdd17dc6-5314-11ea-8841-482eed0038b1\n",
      "https://www.ft.com/content/91addb98-532b-11ea-a1ef-da1721a0541e\n",
      "https://www.ft.com/content/69466c44-549b-11ea-90ad-25e377c0ee1f\n",
      "https://www.ft.com/content/fc1f5c12-54a8-11ea-8841-482eed0038b1\n",
      "https://www.ft.com/content/129955e0-5497-11ea-8841-482eed0038b1\n",
      "https://www.ft.comhttp://ftalphaville.ft.com/2020/02/21/1582279827000/The-under-appreciated-importance-of-non-woven-markets/\n",
      "https://www.ft.com/content/a247239a-53b9-11ea-8841-482eed0038b1\n",
      "https://www.ft.com/content/7c25fce2-53ad-11ea-8841-482eed0038b1\n",
      "https://www.ft.com/content/39177332-52da-11ea-8841-482eed0038b1\n",
      "https://www.ft.com/content/79176178-52f7-11ea-90ad-25e377c0ee1f\n",
      "https://www.ft.com/content/7e5e7620-52f8-11ea-90ad-25e377c0ee1f\n",
      "https://www.ft.com/content/4667b18c-5249-11ea-8841-482eed0038b1\n",
      "https://www.ft.com/content/20f4cfa0-5237-11ea-8841-482eed0038b1\n",
      "https://www.ft.com/content/799ae1a2-5170-11ea-90ad-25e377c0ee1f\n",
      "https://www.ft.com/content/3b23ce8a-5147-11ea-8841-482eed0038b1\n"
     ]
    }
   ],
   "source": [
    "for i in ft_page.find_all('p', class_='o-teaser__standfirst'):\n",
    "    for rs in i.find_all('a'):\n",
    "        \n",
    "        link = rs['href']\n",
    "        url = 'https://www.ft.com'+link\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ft.com/content/52f6df32-58b5-11ea-a528-dd0f971febbc\n"
     ]
    }
   ],
   "source": [
    "print(article_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turkey’s economy grows faster than predicted in second quarter\n"
     ]
    }
   ],
   "source": [
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
